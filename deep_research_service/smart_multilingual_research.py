import asyncio
import aiohttp
import json
from datetime import datetime
import os
import logging
import re
from typing import List, Dict, Any
import time

logger = logging.getLogger(__name__)

class SmartMultilingualResearcher:
    """
    AkÄ±llÄ± Ã§ok dilli araÅŸtÄ±rma sistemi
    - Dil algÄ±lama
    - Ä°teratif web aramasÄ±
    - Ä°Ã§erik kalite deÄŸerlendirmesi
    - MantÄ±ksal Ã§Ä±karÄ±m
    - KapsamlÄ± rapor oluÅŸturma
    """
    
    def __init__(self, model_name, model_source, websocket):
        self.model_name = model_name
        self.model_source = model_source
        self.websocket = websocket
        self.search_results = []
        self.research_data = []
        self.query_language = "auto"
        
    async def call_local_model(self, prompt, system_prompt="", max_tokens=3000):
        """Lokal modeli asenkron olarak Ã§aÄŸÄ±rÄ±r - Ollama ve LM Studio desteÄŸi"""
        try:
            logger.info(f"call_local_model called with model_source: '{self.model_source}', model_name: '{self.model_name}'")
            import socket
            
            # Host IP'yi bul - Docker container'dan host'a eriÅŸim iÃ§in
            try:
                # Docker compose network'te host.docker.internal kullan
                host_ip = socket.gethostbyname('host.docker.internal')
            except:
                # Fallback IP'ler - macOS Docker Desktop iÃ§in
                try:
                    host_ip = "192.168.65.1"  # Docker Desktop default gateway
                except:
                    try:
                        host_ip = "172.17.0.1"  # Docker bridge network
                    except:
                        host_ip = "localhost"

            async with aiohttp.ClientSession() as session:
                logger.info(f"Model source comparison: '{self.model_source}' == 'Ollama' ? {self.model_source == 'Ollama'}")
                if self.model_source == "Ollama":
                    try:
                        # Model yÃ¼kleniyor bildirimi
                        await self.websocket.send_json({
                            "type": "progress", 
                            "step": 0, 
                            "message": f"ğŸ”„ {self.model_name} modeli yÃ¼kleniyor (ilk kullanÄ±mda zaman alabilir)..."
                        })
                        
                        ollama_url = f"http://{host_ip}:11434/api/generate"
                        ollama_payload = {
                            "model": self.model_name,
                            "prompt": f"{system_prompt}\n\nUser: {prompt}\n\nAssistant:",
                            "stream": False,
                            "options": {
                                "temperature": 0.3,
                                "num_predict": max_tokens
                            }
                        }
                        
                        async with session.post(ollama_url, json=ollama_payload, timeout=300) as response:
                            logger.info(f"Ollama request to {ollama_url} with payload: {ollama_payload}")
                            logger.info(f"Ollama response status: {response.status}")
                            if response.status == 200:
                                data = await response.json()
                                return data.get('response', '').strip()
                            else:
                                error_text = await response.text()
                                logger.error(f"Ollama HTTP {response.status} error: {error_text}")
                                return f"Ollama hatasÄ±: {response.status} - {error_text}"
                    except Exception as ollama_error:
                        return f"Ollama hatasÄ±: {ollama_error}"
                
                elif self.model_source == "LM Studio":
                    try:
                        lm_studio_url = f"http://{host_ip}:1234/v1/chat/completions"
                        lm_payload = {
                            "model": self.model_name,
                            "messages": [
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": prompt}
                            ],
                            "temperature": 0.3,
                            "max_tokens": max_tokens,
                            "stream": False
                        }
                        
                        async with session.post(lm_studio_url, json=lm_payload, timeout=120) as response:
                            if response.status == 200:
                                data = await response.json()
                                content = data['choices'][0]['message']['content']
                                return content.strip()
                            else:
                                return f"LM Studio hatasÄ±: {response.status}"
                    except Exception as lm_error:
                        # LM Studio Ã§alÄ±ÅŸmÄ±yorsa Ollama'ya fallback yap
                        logger.warning(f"LM Studio eriÅŸilemez, Ollama'ya geÃ§iliyor: {lm_error}")
                        try:
                            ollama_url = f"http://{host_ip}:11434/api/generate"
                            ollama_payload = {
                                "model": self.model_name,
                                "prompt": f"{system_prompt}\n\nUser: {prompt}\n\nAssistant:",
                                "stream": False,
                                "options": {
                                    "temperature": 0.3,
                                    "num_predict": max_tokens
                                }
                            }
                            
                            async with session.post(ollama_url, json=ollama_payload, timeout=300) as response:
                                if response.status == 200:
                                    data = await response.json()
                                    return data.get('response', '').strip()
                                else:
                                    return f"Hem LM Studio hem Ollama eriÅŸilemez"
                        except:
                            return f"Model baÄŸlantÄ± hatasÄ±: LM Studio Ã§alÄ±ÅŸmÄ±yor, Ollama'ya da eriÅŸilemedi"
                
                else: # Kaynak bilinmiyorsa Ã¶nce LM Studio dene, sonra Ollama
                    try:
                        lm_studio_url = f"http://{host_ip}:1234/v1/chat/completions"
                        lm_payload = {
                            "model": self.model_name,
                            "messages": [
                                {"role": "system", "content": system_prompt},
                                {"role": "user", "content": prompt}
                            ],
                            "temperature": 0.3,
                            "max_tokens": max_tokens,
                            "stream": False
                        }
                        
                        async with session.post(lm_studio_url, json=lm_payload, timeout=120) as response:
                            if response.status == 200:
                                data = await response.json()
                                content = data['choices'][0]['message']['content']
                                return content.strip()
                    except:
                        pass
                    
                    try:
                        ollama_url = f"http://{host_ip}:11434/api/generate"
                        ollama_payload = {
                            "model": self.model_name,
                            "prompt": f"{system_prompt}\n\nUser: {prompt}\n\nAssistant:",
                            "stream": False,
                            "options": {
                                "temperature": 0.3,
                                "num_predict": max_tokens
                            }
                        }
                        
                        async with session.post(ollama_url, json=ollama_payload, timeout=300) as response:
                            if response.status == 200:
                                data = await response.json()
                                return data.get('response', '').strip()
                    except:
                        pass
                
                return "Model baÄŸlantÄ± hatasÄ±: Hem LM Studio hem Ollama eriÅŸilemez"

        except Exception as e:
            return f"Model baÄŸlantÄ± hatasÄ±: {str(e)}"

    async def detect_language(self, text):
        """Metin dilini algÄ±lar ve araÅŸtÄ±rma stratejisi belirler"""
        try:
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.05, 
                "message": "ğŸ” Soru dilini analiz ediyorum..."
            })
            
            # Basit TÃ¼rkÃ§e karakter kontrolÃ¼
            turkish_chars = re.search(r'[Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÄ°Ã–ÅÃœ]', text)
            turkish_words = ['nedir', 'nasÄ±l', 'ne', 'hangi', 'kim', 'nerede', 'niÃ§in', 'neden', 'hakkÄ±nda']
            
            has_turkish = turkish_chars is not None or any(word in text.lower() for word in turkish_words)
            
            if has_turkish:
                self.query_language = "tr"
                await self.websocket.send_json({
                    "type": "progress", 
                    "step": 0.07, 
                    "message": "ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e soru tespit edildi - Ã§ok dilli araÅŸtÄ±rma stratejisi hazÄ±rlanÄ±yor"
                })
                return "turkish"
            else:
                self.query_language = "en"
                await self.websocket.send_json({
                    "type": "progress", 
                    "step": 0.07, 
                    "message": "ğŸ‡ºğŸ‡¸ Ä°ngilizce soru tespit edildi - global araÅŸtÄ±rma stratejisi hazÄ±rlanÄ±yor"
                })
                return "english"
                
        except Exception as e:
            logger.error(f"Language detection error: {e}")
            return "english"

    async def generate_smart_queries(self, topic, language):
        """AkÄ±llÄ± arama sorgularÄ± oluÅŸturur"""
        try:
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.1, 
                "message": "ğŸ§  AkÄ±llÄ± arama stratejisi geliÅŸtiriliyor..."
            })
            
            current_date = datetime.now().strftime("%d %B %Y")
            
            if language == "turkish":
                prompt = f"""
Bu konuyla ilgili 4 farklÄ± arama sorgusu oluÅŸtur:

Konu: {topic}
Tarih: {current_date}

Sorgular ÅŸu aÃ§Ä±lardan olmalÄ±:
1. Temel tanÄ±m ve kavram (TÃ¼rkÃ§e)
2. GÃ¼ncel geliÅŸmeler ve haberler (TÃ¼rkÃ§e)
3. Global perspektif (Ä°ngilizce)
4. Teknik/bilimsel yaklaÅŸÄ±m (Ä°ngilizce)

Her sorguyu ayrÄ± satÄ±rda sadece sorgu olarak yaz, aÃ§Ä±klama ekleme.
"""
            else:
                prompt = f"""
Generate 4 different search queries for this topic:

Topic: {topic}
Date: {current_date}

Queries should cover:
1. Basic definition and concept
2. Recent developments and news
3. Technical/scientific approach
4. Practical applications

Write only the queries, one per line, no explanations.
"""
            
            queries_text = await self.call_local_model(
                prompt, 
                "Sen araÅŸtÄ±rma uzmanÄ±sÄ±n. Etkili web arama sorgularÄ± oluÅŸturursun."
            )
            
            # SorgularÄ± parse et
            search_queries = []
            lines = queries_text.split('\n')
            for line in lines:
                line = line.strip()
                if line and len(line) > 5:
                    # NumaralarÄ± ve fazla iÅŸaretleri temizle
                    query = re.sub(r'^\d+[\.\-\)\s]*', '', line).strip()
                    if query and query not in search_queries:
                        search_queries.append(query)
            
            # Fallback sorgularÄ±
            if not search_queries:
                if language == "turkish":
                    search_queries = [
                        topic,
                        f"{topic} nedir",
                        f"{topic} gÃ¼ncel geliÅŸmeler",
                        f"{topic} english"
                    ]
                else:
                    search_queries = [
                        topic,
                        f"what is {topic}",
                        f"{topic} latest developments",
                        f"{topic} applications"
                    ]
            
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.12, 
                "message": f"ğŸ“ {len(search_queries)} farklÄ± arama sorgusu hazÄ±rlandÄ±"
            })
            
            return search_queries[:4]  # En fazla 4 sorgu
            
        except Exception as e:
            logger.error(f"Query generation error: {e}")
            return [topic]

    async def search_web_advanced(self, query, max_results=5):
        """GeliÅŸmiÅŸ web aramasÄ± - Google ve DuckDuckGo hibrit"""
        try:
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.2, 
                "message": f"ğŸŒ Web'de araÅŸtÄ±rma: '{query[:50]}...'"
            })
            
            import asyncio
            import concurrent.futures
            
            def sync_search():
                results = []
                
                # Ã–nce Google'Ä± dene
                try:
                    from googlesearch import search as google_search
                    import requests
                    from bs4 import BeautifulSoup
                    
                    google_urls = list(google_search(query, num_results=max_results, lang='en'))
                    
                    for url in google_urls[:max_results]:
                        try:
                            response = requests.get(url, timeout=5, headers={
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                            })
                            soup = BeautifulSoup(response.text, 'html.parser')
                            title = soup.find('title')
                            title_text = title.text if title else url
                            
                            meta_desc = soup.find('meta', attrs={'name': 'description'})
                            description = meta_desc.get('content', '') if meta_desc else ''
                            
                            results.append({
                                'title': title_text,
                                'body': description,
                                'href': url,
                                'source': 'Google'
                            })
                        except:
                            continue
                            
                except ImportError:
                    pass
                
                # Google yetersizse DuckDuckGo ekle
                if len(results) < max_results:
                    try:
                        from duckduckgo_search import DDGS
                        ddgs = DDGS()
                        ddg_results = list(ddgs.text(query, max_results=max_results, region='us-en'))
                        
                        for result in ddg_results:
                            if len(results) >= max_results:
                                break
                                
                            title = result.get('title', '').lower()
                            body = result.get('body', '').lower()
                            url = result.get('href', '').lower()
                            
                            # Ã‡ince karakterleri filtrele
                            chinese_pattern = r'[\u4e00-\u9fff]'
                            if (re.search(chinese_pattern, title) or 
                                re.search(chinese_pattern, body) or
                                any(site in url for site in ['zhihu.com', 'baidu.com', 'weibo.com'])):
                                continue
                            
                            result['source'] = 'DuckDuckGo'
                            results.append(result)
                    except:
                        pass
                
                return results
            
            # Sync search'Ã¼ thread pool'da Ã§alÄ±ÅŸtÄ±r
            with concurrent.futures.ThreadPoolExecutor() as executor:
                search_results = await asyncio.get_event_loop().run_in_executor(
                    executor, sync_search
                )
            
            return search_results
            
        except Exception as e:
            logger.error(f"Advanced web search error: {e}")
            return []

    async def extract_and_analyze_content(self, url, title):
        """URL'den iÃ§erik Ã§eker ve AI ile analiz eder"""
        try:
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.3, 
                "message": f"ğŸ“– Ä°Ã§erik analiz ediliyor: {title[:40]}..."
            })
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=15) as response:
                    if response.status == 200:
                        html = await response.text()
                        
                        # HTML temizleme
                        try:
                            from bs4 import BeautifulSoup
                            soup = BeautifulSoup(html, 'html.parser')
                            
                            # Script ve style etiketlerini kaldÄ±r
                            for script in soup(["script", "style", "nav", "footer", "header"]):
                                script.decompose()
                            
                            # Text'i al
                            text = soup.get_text()
                            
                            # SatÄ±rlarÄ± temizle
                            lines = (line.strip() for line in text.splitlines())
                            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
                            clean_text = ' '.join(chunk for chunk in chunks if chunk)
                            
                            return clean_text[:4000]  # Ä°lk 4000 karakter
                            
                        except ImportError:
                            # BeautifulSoup yoksa basit text extract
                            import re
                            text = re.sub('<[^<]+?>', '', html)
                            return text[:4000]
            
        except Exception as e:
            logger.error(f"Content extraction error for {url}: {e}")
            return ""

    async def evaluate_source_reliability(self, source_data):
        """Kaynak gÃ¼venilirliÄŸini AI ile deÄŸerlendirir"""
        try:
            prompt = f"""
Bu web kaynaÄŸÄ±nÄ±n gÃ¼venilirliÄŸini 1-10 arasÄ±nda puanla:

BaÅŸlÄ±k: {source_data.get('title', '')}
URL: {source_data.get('href', '')}
Ä°Ã§erik: {source_data.get('content', '')[:500]}...

DeÄŸerlendirme kriterleri:
- Kaynak otoritesi (domain gÃ¼venilirliÄŸi)
- Ä°Ã§erik kalitesi ve derinliÄŸi
- GÃ¼ncellik
- Objektiflik

Sadece puanÄ± ver (1-10) ve kÄ±sa gerekÃ§e.
Format: "Puan: X/10 - GerekÃ§e"
"""
            
            evaluation = await self.call_local_model(
                prompt,
                "Sen kaynak gÃ¼venilirlik uzmanÄ±sÄ±n. Web kaynaklarÄ±nÄ± objektif deÄŸerlendirirsin.",
                max_tokens=200
            )
            
            # PuanÄ± Ã§Ä±kar
            score_match = re.search(r'(\d+)/10', evaluation)
            score = int(score_match.group(1)) if score_match else 5
            
            return {
                'score': score,
                'evaluation': evaluation,
                'reliable': score >= 6
            }
            
        except Exception as e:
            logger.error(f"Source evaluation error: {e}")
            return {'score': 5, 'evaluation': 'DeÄŸerlendirilemedi', 'reliable': True}

    async def iterative_research_analysis(self, topic, research_data):
        """Ä°teratif araÅŸtÄ±rma analizi - eksik alanlarÄ± tespit eder"""
        try:
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.7, 
                "message": "ğŸ”„ AraÅŸtÄ±rma eksikliklerini tespit ediyorum..."
            })
            
            # Mevcut araÅŸtÄ±rma verilerini Ã¶zetle
            current_summary = "\n".join([
                f"- {item['source']}: {item['analysis'][:100]}..."
                for item in research_data[:5]
            ])
            
            prompt = f"""
Bu konudaki mevcut araÅŸtÄ±rma verilerini analiz et ve eksik alanlarÄ± tespit et:

Konu: {topic}

Mevcut veriler:
{current_summary}

Eksik kalan Ã¶nemli alanlarÄ± listele:
1. Hangi konular eksik?
2. Hangi bakÄ±ÅŸ aÃ§Ä±larÄ± kayÄ±p?
3. GÃ¼ncel geliÅŸmeler var mÄ±?

Sadece en Ã¶nemli 2-3 eksik alanÄ± belirt.
"""
            
            gap_analysis = await self.call_local_model(
                prompt,
                "Sen araÅŸtÄ±rma kalite kontrol uzmanÄ±sÄ±n. AraÅŸtÄ±rmalardaki eksikleri tespit edersin.",
                max_tokens=500
            )
            
            # Eksik alanlarÄ± parse et
            gaps = []
            lines = gap_analysis.split('\n')
            for line in lines:
                line = line.strip()
                if line and ('eksik' in line.lower() or 'kayÄ±p' in line.lower() or 'yok' in line.lower()):
                    gaps.append(line)
            
            return gaps[:3]  # En fazla 3 eksik alan
            
        except Exception as e:
            logger.error(f"Gap analysis error: {e}")
            return []

    async def run_research(self, topic):
        """Ana araÅŸtÄ±rma fonksiyonu - tÃ¼m sÃ¼reci yÃ¶netir"""
        try:
            start_time = time.time()
            
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.01, 
                "message": f"ğŸš€ '{topic}' iÃ§in akÄ±llÄ± Ã§ok dilli araÅŸtÄ±rma baÅŸlÄ±yor..."
            })
            
            # 1. Dil algÄ±lama
            language = await self.detect_language(topic)
            
            # 2. AkÄ±llÄ± sorgu oluÅŸturma
            queries = await self.generate_smart_queries(topic, language)
            
            # 3. Web araÅŸtÄ±rmasÄ±
            all_results = []
            for i, query in enumerate(queries):
                await self.websocket.send_json({
                    "type": "progress", 
                    "step": 0.15 + (i * 0.15), 
                    "message": f"ğŸ” Arama {i+1}/{len(queries)}: {query[:50]}..."
                })
                
                results = await self.search_web_advanced(query, max_results=4)
                all_results.extend(results)
                
                await asyncio.sleep(1)  # Rate limiting
            
            # 4. Ä°Ã§erik analizi
            research_data = []
            for i, result in enumerate(all_results[:10]):  # Ä°lk 10 sonuÃ§
                await self.websocket.send_json({
                    "type": "progress", 
                    "step": 0.5 + (i * 0.03), 
                    "message": f"ğŸ“Š Kaynak analizi: {result['title'][:30]}..."
                })
                
                # Ä°Ã§erik Ã§ek
                content = await self.extract_and_analyze_content(result['href'], result['title'])
                result['content'] = content
                
                # GÃ¼venilirlik deÄŸerlendir
                reliability = await self.evaluate_source_reliability(result)
                result['reliability'] = reliability
                
                # Sadece gÃ¼venilir kaynaklarÄ± al
                if reliability['reliable'] and content:
                    analysis_prompt = f"""
Bu web kaynaÄŸÄ±ndaki bilgileri '{topic}' konusu iÃ§in Ã¶zetle:

Kaynak: {result['title']}
Ä°Ã§erik: {content[:2000]}

Sadece konuyla ilgili Ã¶nemli bilgileri Ã¶zetle.
"""
                    
                    analysis = await self.call_local_model(
                        analysis_prompt,
                        "Sen araÅŸtÄ±rma analistisin. Web kaynaklarÄ±nÄ± Ã¶zetlersin.",
                        max_tokens=800
                    )
                    
                    if analysis and "hatasÄ±" not in analysis.lower():
                        research_data.append({
                            'source': result['title'],
                            'url': result['href'],
                            'analysis': analysis,
                            'reliability_score': reliability['score'],
                            'search_source': result.get('source', 'Unknown')
                        })
            
            # 5. Eksiklik analizi (opsiyonel)
            gaps = await self.iterative_research_analysis(topic, research_data)
            
            # 6. Final rapor
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.9, 
                "message": "ğŸ“ KapsamlÄ± araÅŸtÄ±rma raporu hazÄ±rlanÄ±yor..."
            })
            
            report = await self.generate_comprehensive_report(topic, research_data, language, gaps)
            
            # 7. Performans metrikleri
            end_time = time.time()
            duration = end_time - start_time
            
            await self.websocket.send_json({
                "type": "progress", 
                "step": 1.0, 
                "message": f"âœ… AraÅŸtÄ±rma tamamlandÄ±! ({duration:.1f}s, {len(research_data)} kaynak)"
            })
            
            return report
            
        except Exception as e:
            logger.error(f"Research process error: {e}")
            return f"AraÅŸtÄ±rma hatasÄ±: {str(e)}"

    async def generate_comprehensive_report(self, topic, research_data, language, gaps):
        """KapsamlÄ± araÅŸtÄ±rma raporu oluÅŸturur"""
        try:
            # AraÅŸtÄ±rma verilerini birleÅŸtir
            combined_research = "\n\n".join([
                f"**Kaynak: {item['source']}** (GÃ¼venilirlik: {item['reliability_score']}/10)\nURL: {item['url']}\nAraÅŸtÄ±rma Motoru: {item['search_source']}\n{item['analysis']}"
                for item in research_data
            ])
            
            # Eksiklik bilgisi
            gaps_text = "\n".join([f"- {gap}" for gap in gaps]) if gaps else "KapsamlÄ± araÅŸtÄ±rma tamamlandÄ±."
            
            current_date = datetime.now().strftime("%d %B %Y")
            
            if language == "turkish":
                final_prompt = f"""
AÅŸaÄŸÄ±daki araÅŸtÄ±rma sonuÃ§larÄ±nÄ± kullanarak '{topic}' konusu hakkÄ±nda TÃ¼rkÃ§e kapsamlÄ± bir rapor hazÄ±rla:

ARAÅTIRMA VERÄ°LERÄ°:
{combined_research}

EKSÄ°K ALANLAR:
{gaps_text}

RAPOR Ä°HTÄ°YAÃ‡LARI:
- Tamamen TÃ¼rkÃ§e yazÄ±lmÄ±ÅŸ olmasÄ±
- Net giriÅŸ ve Ã¶zet
- Ana bulgular ve Ã¶nemli geliÅŸmeler
- Kaynaklara dayalÄ± detaylÄ± analiz
- GÃ¼ncel durum deÄŸerlendirmesi
- SonuÃ§ ve gelecek Ã¶ngÃ¶rÃ¼leri
- Markdown formatÄ±nda dÃ¼zenli yapÄ±

Ã–zellikle {current_date} tarihi itibariyle gÃ¼ncel ve bilimsel bir rapor oluÅŸtur.
"""
            else:
                final_prompt = f"""
Create a comprehensive English report about '{topic}' using the following research data:

RESEARCH DATA:
{combined_research}

IDENTIFIED GAPS:
{gaps_text}

REPORT REQUIREMENTS:
- Professional English writing
- Clear introduction and summary
- Key findings and developments
- Source-based detailed analysis
- Current status assessment
- Conclusions and future outlook
- Well-structured Markdown format

Focus on current information as of {current_date}.
"""
            
            final_report = await self.call_local_model(
                final_prompt,
                "Sen uzman araÅŸtÄ±rmacÄ±sÄ±sÄ±n. Web araÅŸtÄ±rmasÄ± sonuÃ§larÄ±ndan kapsamlÄ±, profesyonel raporlar yazarsÄ±n.",
                max_tokens=5000
            )
            
            # Rapor baÅŸlÄ±ÄŸÄ± ve meta bilgileri
            header = f"""# AkÄ±llÄ± Ã‡ok Dilli AraÅŸtÄ±rma: {topic}

**AraÅŸtÄ±rma Tarihi:** {datetime.now().strftime('%d %B %Y, %H:%M')}
**AraÅŸtÄ±rma TÃ¼rÃ¼:** AkÄ±llÄ± Ã‡ok Dilli Web AraÅŸtÄ±rmasÄ±
**KullanÄ±lan Model:** {self.model_name} ({self.model_source})
**Toplam Kaynak:** {len(research_data)} gÃ¼venilir web kaynaÄŸÄ±
**AraÅŸtÄ±rma Dili:** {language.title()}
**Arama MotorlarÄ±:** Google, DuckDuckGo

---

"""
            
            # Kaynak listesi
            source_list = "\n".join([
                f"- [{item['source']}]({item['url']}) - GÃ¼venilirlik: {item['reliability_score']}/10 ({item['search_source']})"
                for item in research_data
            ])
            
            full_report = header + final_report + f"\n\n## ğŸ“š Kaynaklar\n\n{source_list}"
            
            # Dosya kaydetme
            await self.save_research_report(topic, full_report)
            
            return full_report
            
        except Exception as e:
            logger.error(f"Report generation error: {e}")
            return f"Rapor oluÅŸturma hatasÄ±: {str(e)}"

    async def save_research_report(self, topic, report):
        """AraÅŸtÄ±rma raporunu dosyaya kaydeder"""
        try:
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.95, 
                "message": "ğŸ’¾ Rapor kaydediliyor..."
            })
            
            import os
            from pathlib import Path
            
            # MasaÃ¼stÃ¼ yolunu bul
            home = Path.home()
            desktop = home / "Desktop"
            
            # Dosya adÄ± oluÅŸtur
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_topic = "".join(c for c in topic if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
            filename = f"{timestamp}_{safe_topic.replace(' ', '_')}_smart_research.md"
            
            # MasaÃ¼stÃ¼ne kaydet
            filepath = desktop / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(report)
            
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.98, 
                "message": f"âœ… Rapor masaÃ¼stÃ¼ne kaydedildi: {filename}"
            })
            
        except Exception as e:
            logger.error(f"Report save error: {e}")
            await self.websocket.send_json({
                "type": "progress", 
                "step": 0.98, 
                "message": f"âš ï¸ Dosya kaydetme hatasÄ±: {str(e)}"
            })