import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from pydantic import BaseModel
import sys
import os
import json

# Add the src directory to the Python path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from real_deep_research import RealDeepResearcher
from smart_multilingual_research import SmartMultilingualResearcher
import asyncio
import logging

# Setup logging
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = FastAPI()

# Lokal model test fonksiyonlarÄ±
async def test_lm_studio():
    """LM Studio'nun Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± test eder"""
    try:
        import aiohttp
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:1234/v1/models", timeout=5) as response:
                return response.status == 200
    except:
        return False



class LocalDeepResearcher:
    """Tamamen lokal modellerle Ã§alÄ±ÅŸan derin araÅŸtÄ±rma sÄ±nÄ±fÄ±"""
    
    def __init__(self, model_name, websocket):
        self.model_name = model_name
        self.websocket = websocket
        
    def call_local_model(self, prompt, system_prompt=""):
        """Lokal modeli Ã§aÄŸÄ±rÄ±r - sync version with requests"""
        try:
            import requests
            
            payload = {
                "model": self.model_name,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 2000
            }
            
            # Docker container'dan LM Studio'ya eriÅŸim iÃ§in host IP kullan
            import socket
            try:
                # Docker container'dan host makineye eriÅŸim
                host_ip = socket.gethostbyname('host.docker.internal')
                lm_studio_url = f"http://{host_ip}:1234/v1/chat/completions"
            except:
                # Fallback for other systems or if host.docker.internal fails
                lm_studio_url = "http://localhost:1234/v1/chat/completions"
            
            response = requests.post(
                lm_studio_url, 
                json=payload, 
                timeout=600  # 10 dakika timeout - derin araÅŸtÄ±rma uzun sÃ¼rer
            )
            
            if response.status_code == 200:
                data = response.json()
                content = data['choices'][0]['message']['content']
                return content
            else:
                error_msg = f"LM Studio HTTP hatasÄ±: {response.status_code} - {response.text}"
                return error_msg
                
        except requests.exceptions.Timeout:
            return "â° Model yavaÅŸ yanÄ±t veriyor - daha kÃ¼Ã§Ã¼k bir model deneyin"
        except Exception as e:
            return f"LM Studio baÄŸlantÄ± hatasÄ±: {str(e)}"
    
    async def research_topic(self, topic):
        """Tamamen lokal derin araÅŸtÄ±rma yapar - detaylÄ± dÃ¼ÅŸÃ¼nme sÃ¼reciyle"""
        
        await self.websocket.send_json({"type": "progress", "step": 0.05, "message": "ğŸ¤” Konuyu analiz etmeye baÅŸlÄ±yorum..."})
        await asyncio.sleep(1)
        
        await self.websocket.send_json({"type": "progress", "step": 0.08, "message": f"ğŸ“‹ '{topic}' konusu iÃ§in araÅŸtÄ±rma stratejisi belirliyorum..."})
        await asyncio.sleep(1)
        
        # 1. Ä°lk araÅŸtÄ±rma planÄ±
        await self.websocket.send_json({"type": "progress", "step": 0.1, "message": "ğŸ§  Hangi bilgi tÃ¼rlerini araÅŸtÄ±rmam gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum..."})
        
        analysis_prompt = f"""
AÅŸaÄŸÄ±daki araÅŸtÄ±rma konusunu analiz et ve hangi alt konularÄ±n araÅŸtÄ±rÄ±lmasÄ± gerektiÄŸini belirle:

Konu: {topic}

LÃ¼tfen ÅŸu formatta yanÄ±tla:
1. Ana konu Ã¶zeti
2. AraÅŸtÄ±rÄ±lmasÄ± gereken alt konular (5-7 tane)
3. Bu konuyla ilgili Ã¶nemli noktalar
"""
        
        await self.websocket.send_json({"type": "progress", "step": 0.12, "message": "ğŸ” Model ile konu planÄ±nÄ± hazÄ±rlÄ±yorum..."})
        analysis = self.call_local_model(analysis_prompt, "Sen detaylÄ± araÅŸtÄ±rma yapan bir AI asistansÄ±n.")
        
        await self.websocket.send_json({"type": "progress", "step": 0.15, "message": "âœ… AraÅŸtÄ±rma planÄ± hazÄ±r! Alt konularÄ± belirliyorum..."})
        await asyncio.sleep(1)
        
        # Alt konularÄ± Ã§Ä±kar
        subtopics = []
        lines = analysis.split('\n')
        for line in lines:
            if any(marker in line for marker in ['1.', '2.', '3.', '4.', '5.', '-', '*']):
                clean_line = line.strip('1234567890.-* ')
                if len(clean_line) > 10:  # AnlamlÄ± alt konular
                    subtopics.append(clean_line)
        
        await self.websocket.send_json({"type": "progress", "step": 0.18, "message": f"ğŸ“š {len(subtopics)} farklÄ± aÃ§Ä±dan konuyu araÅŸtÄ±racaÄŸÄ±m..."})
        await asyncio.sleep(1)
        
        # SimÃ¼le kaynak listesi
        simulated_sources = [
            "Model bilgi tabanÄ± - Temel kavramlar",
            "Model bilgi tabanÄ± - Teknik detaylar", 
            "Model bilgi tabanÄ± - GÃ¼ncel geliÅŸmeler",
            "Model bilgi tabanÄ± - Pratik uygulamalar",
            "Model bilgi tabanÄ± - KarÅŸÄ±laÅŸtÄ±rmalar",
            "Model bilgi tabanÄ± - Uzman gÃ¶rÃ¼ÅŸleri"
        ]
        
        detailed_research = []
        collected_info = []
        
        for i, subtopic in enumerate(subtopics[:5]):  # Max 5 alt konu
            base_progress = 0.2 + (0.5 * i / len(subtopics[:5]))
            
            await self.websocket.send_json({"type": "progress", "step": base_progress, "message": f"ğŸ” '{subtopic[:60]}...' konusunu araÅŸtÄ±rÄ±yorum"})
            await asyncio.sleep(1)
            
            # Kaynak seÃ§imi simÃ¼lasyonu
            selected_source = simulated_sources[i % len(simulated_sources)]
            await self.websocket.send_json({"type": "progress", "step": base_progress + 0.02, "message": f"ğŸ“– {selected_source} kaynaÄŸÄ±nÄ± inceliyorum..."})
            await asyncio.sleep(2)
            
            # Bilgi toplama simÃ¼lasyonu
            await self.websocket.send_json({"type": "progress", "step": base_progress + 0.04, "message": f"ğŸ’­ Bu kaynakta '{subtopic}' hakkÄ±nda ne var bakalÄ±m..."})
            await asyncio.sleep(1)
            
            research_prompt = f"""
"{subtopic}" konusu hakkÄ±nda detaylÄ± bilgi ver. Ã–zellikle "{topic}" ana konusu baÄŸlamÄ±nda:

- Temel kavramlar ve tanÄ±mlar
- Ã–nemli Ã¶zellikler ve karakteristikler  
- Avantajlar ve dezavantajlar
- GÃ¼ncel durum ve geliÅŸmeler
- Pratik uygulamalar

DetaylÄ± ve bilgilendirici bir aÃ§Ä±klama yap.
"""
            
            research = self.call_local_model(research_prompt, "Sen uzman bir araÅŸtÄ±rmacÄ±sÄ±n. Objektif ve detaylÄ± bilgi verirsin.")
            
            # Bilgi deÄŸerlendirmesi
            await self.websocket.send_json({"type": "progress", "step": base_progress + 0.06, "message": f"ğŸ¤“ Bulunan bilgiyi analiz ediyorum... ({len(research)} karakter bilgi toplandÄ±)"})
            await asyncio.sleep(1)
            
            # Yeterlilik kontrolÃ¼ simÃ¼lasyonu
            if len(research) > 200:
                await self.websocket.send_json({"type": "progress", "step": base_progress + 0.08, "message": f"âœ… '{subtopic}' iÃ§in yeterli detay buldum!"})
                detailed_research.append(f"## {subtopic}\n\n{research}")
                collected_info.append(f"âœ“ {subtopic}: {len(research)} karakter ({selected_source})")
            else:
                await self.websocket.send_json({"type": "progress", "step": base_progress + 0.08, "message": f"âš ï¸ '{subtopic}' iÃ§in bilgi az, baÅŸka aÃ§Ä±dan bakayÄ±m..."})
                # Alternatif araÅŸtÄ±rma
                alt_prompt = f"'{subtopic}' konusu hakkÄ±nda farklÄ± bir perspektiften daha detaylÄ± bilgi ver."
                alt_research = self.call_local_model(alt_prompt, "FarklÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla detaylÄ± bilgi ver.")
                detailed_research.append(f"## {subtopic}\n\n{research}\n\n### Ek Bilgiler\n{alt_research}")
                collected_info.append(f"âœ“ {subtopic}: {len(research + alt_research)} karakter (alternatif araÅŸtÄ±rma)")
                await self.websocket.send_json({"type": "progress", "step": base_progress + 0.09, "message": f"ğŸ’¡ Alternatif perspektifle daha iyi bilgi topladÄ±m!"})
            
            await asyncio.sleep(1)
        
        # Toplam bilgi Ã¶zeti
        total_chars = sum(len(r) for r in detailed_research)
        await self.websocket.send_json({"type": "progress", "step": 0.75, "message": f"ğŸ“Š Toplamda {total_chars} karakter bilgi topladÄ±m. Yeterli mi kontrol ediyorum..."})
        await asyncio.sleep(1)
        
        if total_chars > 3000:
            await self.websocket.send_json({"type": "progress", "step": 0.77, "message": "âœ… Toplanan bilgi kapsamlÄ±! Final rapor hazÄ±rlayabilirim."})
        else:
            await self.websocket.send_json({"type": "progress", "step": 0.77, "message": "âš ï¸ Daha fazla detay gerekebilir, raporu optimize ediyorum..."})
            
        await asyncio.sleep(1)
        
        # Kaynak Ã¶zeti gÃ¶sterimi  
        await self.websocket.send_json({"type": "progress", "step": 0.8, "message": "ğŸ“‹ Toplanan bilgi Ã¶zeti:"})
        await asyncio.sleep(0.5)
        
        for info in collected_info:
            await self.websocket.send_json({"type": "progress", "step": 0.81, "message": f"  {info}"})
            await asyncio.sleep(0.3)
        
        await self.websocket.send_json({"type": "progress", "step": 0.85, "message": "ğŸ“ Åimdi tÃ¼m bilgileri dÃ¼zenli bir rapor haline getiriyorum..."})
        await asyncio.sleep(2)
        
        # Final rapor oluÅŸturma
        final_prompt = f"""
AÅŸaÄŸÄ±daki araÅŸtÄ±rma verilerini kullanarak "{topic}" konusu hakkÄ±nda kapsamlÄ± ve iyi organize edilmiÅŸ bir rapor hazÄ±rla:

ARAÅTIRMA VERÄ°LERÄ°:
{chr(10).join(detailed_research)}

RAPOR REQUÄ°REMENTS:
- BaÅŸlÄ±k ve giriÅŸ
- Ana bÃ¶lÃ¼mler halinde organize edilmiÅŸ iÃ§erik
- SonuÃ§ ve Ã¶zetler
- Markdown formatÄ±nda
- DetaylÄ± ve profesyonel

Tamamen lokal model bilgilerine dayalÄ±, kapsamlÄ± bir araÅŸtÄ±rma raporu oluÅŸtur.
"""
        
        await self.websocket.send_json({"type": "progress", "step": 0.9, "message": "ğŸ¯ Model final raporu yazÄ±yor..."})
        final_report = self.call_local_model(final_prompt, "Sen profesyonel rapor yazarÄ±sÄ±n. Ä°yi organize edilmiÅŸ, kapsamlÄ± ve anlaÅŸÄ±lÄ±r raporlar yazarsÄ±n.")
        
        await self.websocket.send_json({"type": "progress", "step": 0.95, "message": "âœ… Rapor tamamlandÄ±! Son kontroller yapÄ±lÄ±yor..."})
        await asyncio.sleep(1)
        
        # Lokal araÅŸtÄ±rma bildirimi ekle
        local_note = f"""
---

**ğŸ  Lokal AraÅŸtÄ±rma Raporu**

- **Model:** {self.model_name}
- **Toplam Bilgi:** {total_chars:,} karakter
- **AraÅŸtÄ±rÄ±lan Alt Konular:** {len(subtopics)}
- **KullanÄ±lan Kaynaklar:** {len(collected_info)} farklÄ± model perspektifi
- **AraÅŸtÄ±rma TÃ¼rÃ¼:** Tamamen lokal (internet aramasÄ± yok)

Bu araÅŸtÄ±rma tamamen sizin bilgisayarÄ±nÄ±zdaki AI modeli tarafÄ±ndan yapÄ±lmÄ±ÅŸtÄ±r.

---

"""
        
        full_report = local_note + final_report
        
        # Dosya kaydetme iÅŸlemi
        await self.websocket.send_json({"type": "progress", "step": 0.97, "message": "ğŸ’¾ Raporu dosyaya kaydediyorum..."})
        
        try:
            import os
            from datetime import datetime
            
            os.makedirs('/app/research_results', exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            safe_topic = "".join(c for c in topic if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
            filename = f"/app/research_results/{timestamp}_{safe_topic.replace(' ', '_')}.md"
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# Deep Research: {topic}\n\n")
                f.write(f"**Tarih:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**Model:** {self.model_name}\n")
                f.write(f"**Mod:** Tamamen Lokal\n\n")
                f.write("---\n\n")
                f.write(full_report)
            
            await self.websocket.send_json({"type": "progress", "step": 0.99, "message": f"ğŸ“ Rapor kaydedildi: {os.path.basename(filename)}"})
            
        except Exception as e:
            await self.websocket.send_json({"type": "progress", "step": 0.99, "message": f"âš ï¸ Dosya kaydetme hatasÄ±: {str(e)}"})
        
        await self.websocket.send_json({"type": "progress", "step": 1.0, "message": "ğŸ‰ Deep research tamamlandÄ±!"})
        
        return full_report

class ResearchRequest(BaseModel):
    topic: str
    model: str | None = None  # Ä°steÄŸe baÄŸlÄ± model adÄ±

# VarsayÄ±lan modeller - Lokal LM Studio/Ollama
DEFAULT_PLANNING_MODEL = "lmstudio://localhost:1234/v1"
DEFAULT_SUMMARIZATION_MODEL = "lmstudio://localhost:1234/v1"
DEFAULT_JSON_MODEL = "lmstudio://localhost:1234/v1"
DEFAULT_ANSWER_MODEL = "lmstudio://localhost:1234/v1"

print("INFO: LocoDex Deep Research - Tamamen Lokal Mod")
print("INFO: API anahtarlarÄ± gereksiz - sadece lokal modeller kullanÄ±lÄ±yor")

# PaylaÅŸÄ±lan researcher
researcher = None

@app.post("/research")
async def research_http(request: ResearchRequest):
    """
    Conducts deep research on a given topic using the DeepResearcher agent via HTTP.
    """
    try:
        answer = await researcher.research_topic(request.topic)
        return {"status": "success", "answer": answer}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.websocket("/research_ws")
async def research_websocket(websocket: WebSocket):
    await websocket.accept()
    logger.info("WebSocket connection established")
    
    # Ä°lk baÄŸlantÄ± mesajÄ± gÃ¶nder
    await websocket.send_json({"type": "progress", "step": 0, "message": "BaÄŸlantÄ± kuruldu, araÅŸtÄ±rma isteÄŸi bekleniyor..."})
    
    # Keepalive task baÅŸlat
    async def keepalive_task():
        while True:
            try:
                await asyncio.sleep(30)  # Her 30 saniyede bir ping
                await websocket.send_json({"type": "keepalive"})
                logger.info("Keepalive ping sent")
            except Exception as e:
                logger.error(f"Keepalive error: {e}")
                break
    
    keepalive = asyncio.create_task(keepalive_task())
    
    try:
        while True:
            logger.info("Waiting for message...")
            try:
                # WebSocket receive timeout ekle - daha uzun sÃ¼re bekle
                data = await asyncio.wait_for(websocket.receive_text(), timeout=300)  # 5 dakika
                logger.info(f"RAW MESSAGE RECEIVED: {data}")
            except asyncio.TimeoutError:
                logger.info("WebSocket receive timeout - sending keepalive")
                await websocket.send_json({"type": "keepalive", "message": "BaÄŸlantÄ± aktif, araÅŸtÄ±rma isteÄŸi bekleniyor..."})
                continue
            
            try:
                request = json.loads(data)
                logger.info(f"PARSED MESSAGE: {request}")
            except json.JSONDecodeError as e:
                logger.error(f"JSON PARSE ERROR: {e}")
                await websocket.send_json({"type": "error", "data": f"JSON hatasÄ±: {str(e)}"})
                continue
            
            # Ping mesajlarÄ±nÄ± ele al
            if request.get("type") == "ping":
                logger.info("Ping received, ignoring.")
                continue

            topic = request.get("topic")
            model_info = request.get("model")  # Client'ten gelen { id: "model_name", source: "provider" } formatÄ±

            if not topic:
                logger.error("Topic is missing from request")
                await websocket.send_json({"type": "error", "data": "Topic is required"})
                continue

            # Model adÄ± ve kaynaÄŸÄ±nÄ± parse et
            if isinstance(model_info, dict):
                model_name = model_info.get('id', 'default')
                model_source = model_info.get('source', 'Unknown')
            else:
                # Fallback - eski string format
                model_name = str(model_info) if model_info else 'default'
                model_source = 'Unknown'

            logger.info(f"TOPIC: {topic}, MODEL: {model_info}")
            logger.info(f"Full request: {request}")
            logger.info(f"Skipping model test, proceeding with research for: {model_info}")
            logger.info(f"Processing research for topic: '{topic}' with model: {model_name} from {model_source}")

            # Smart multilingual research bildirimi
            await websocket.send_json({"type": "progress", "step": 0, "message": "ğŸŒ AkÄ±llÄ± Ã§ok dilli araÅŸtÄ±rma baÅŸlÄ±yor..."})

            # Yeni akÄ±llÄ± Ã§ok dilli sistem kullan
            researcher = SmartMultilingualResearcher(
                model_name=model_name,
                model_source=model_source,
                websocket=websocket
            )

            try:
                # Model yÃ¼klendi bildirimi gÃ¶nder
                await websocket.send_json({"type": "progress", "step": 0, "message": f"ğŸ¤– Model hazÄ±r: {model_name} ({model_source})"})
                
                # AraÅŸtÄ±rma baÅŸlÄ±yor bildirimi  
                await websocket.send_json({"type": "progress", "step": 0.05, "message": f"ğŸš€ '{topic}' konusu iÃ§in akÄ±llÄ± Ã§ok dilli araÅŸtÄ±rma baÅŸlatÄ±lÄ±yor..."})
                
                # Yeni run_research metodunu Ã§aÄŸÄ±r
                answer = await researcher.run_research(topic)
                await websocket.send_json({"type": "result", "data": answer})
                
            except Exception as e:
                logger.error(f"Research error: {str(e)}")
                await websocket.send_json({"type": "error", "data": f"AraÅŸtÄ±rma hatasÄ±: {str(e)}"})
                # WebSocket baÄŸlantÄ±sÄ±nÄ± devam ettir, hata yÃ¼zÃ¼nden kapatma
                continue

    except WebSocketDisconnect:
        logger.info("Client disconnected.")
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")
    finally:
        keepalive.cancel()
        try:
            await keepalive
        except asyncio.CancelledError:
            logger.info("Keepalive task cancelled.")
        if not websocket.client_state == "DISCONNECTED":
            await websocket.close()
            logger.info("WebSocket connection closed.")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)
